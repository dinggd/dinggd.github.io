<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.1//EN"
  "http://www.w3.org/TR/xhtml11/DTD/xhtml11.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" xml:lang="en">
<head>
<meta name="generator" content="jemdoc, see http://jemdoc.jaboc.net/" />
<meta http-equiv="Content-Type" content="text/html;charset=utf-8" />
<link rel="stylesheet" href="jemdoc.css" type="text/css" />
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/4.7.0/css/font-awesome.min.css">
<link rel="stylesheet" href="../project.css" type="text/css" />
<title>Condensing Action Segmentation Datasets via Generative Network Inversion</title>
<!-- MathJax -->
<script src='https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/latest.js?config=TeX-MML-AM_CHTML' async>
</script>
<script type="text/x-mathjax-config">
MathJax.Hub.Config({
	  TeX: { equationNumbers: { autoNumber: "AMS" } }
});
</script>
<!-- End MathJax -->
</head>
<body>
<div id="layout-content">
<div id="toptitle">
<h1>Condensing Action Segmentation Datasets via Generative Network Inversion</h1>
</div>
<table class="imgtable"><tr><td>
<img src="cas.jpg" alt="" width="707px" height="330px" />&nbsp;</td>
<td align="left"></td></tr></table>
<h2>Authors</h2>
<p><a href="http://www.guodongding.cn" target=&ldquo;blank&rdquo;>Guodong Ding</a>, <a href="https://gloryyrolg.github.io/" target=&ldquo;blank&rdquo;>Rongyu Chen</a> and <a href="https://www.comp.nus.edu.sg/~ayao/" target=&ldquo;blank&rdquo;>Angela Yao</a> <br> National University of Singapore
</p>
<h2>Abstract</h2>
<p>This work presents the first condensation approach for procedural video datasets used in temporal action segmentation. We propose a condensation framework that leverages generative prior learned from the dataset and network inversion to condense data into compact latent codes with significant storage reduced across temporal and channel aspects. Orthogonally, we propose sampling diverse and representative action sequences to minimize video-wise redundancy. Our evaluation on standard benchmarks demonstrates consistent effectiveness in condensing TAS datasets and achieving competitive performances. Specifically, on the Breakfast dataset, our approach reduces storage by over 500\(\times\) while retaining 83% of the performance compared to training with the full dataset. Furthermore, when applied to a downstream incremental learning task, it yields superior performance compared to the state-of-the-art.




</p>
<h2>Resources</h2>
<p>Files: [<a href="../../papers/ding2025condensing.pdf" target=&ldquo;blank&rdquo;>pdf</a>]
</p>
<p>Poster: [<a href="../../papers/ding2025condensing_poster.pdf" target=&ldquo;blank&rdquo;>pdf</a>]
</p>
<p>Citation:
</p>
<div class="infoblock">
<div class="blockcontent">
<p>@inproceedings{ding2025condensing,<br />
title={Condensing Action Segmentation Datasets via Generative Network Inversion},<br />
author={Ding, Guodong and Chen, Rongyu and Yao, Angela},<br />
booktitle={Computer Vision and Pattern Recognition},<br />
year={2025}<br />
}<br />
</p>
</div></div>
</div>
