# jemdoc: addcss{../project.css}
# jemdoc: nofooter
= Condensing Action Segmentation Datasets via Generative Network Inversion

~~~
{}{img_left}{cas.jpg}{}{707px}{330px}{}
~~~

== Authors
[http://www.guodongding.cn Guodong Ding], [https://gloryyrolg.github.io/ Rongyu Chen] and [https://www.comp.nus.edu.sg/~ayao/ Angela Yao] {{<br>}} National University of Singapore
== Abstract
This work presents the first condensation approach for procedural video datasets used in temporal action segmentation. We propose a condensation framework that leverages generative prior learned from the dataset and network inversion to condense data into compact latent codes with significant storage reduced across temporal and channel aspects. Orthogonally, we propose sampling diverse and representative action sequences to minimize video-wise redundancy. Our evaluation on standard benchmarks demonstrates consistent effectiveness in condensing TAS datasets and achieving competitive performances. Specifically, on the Breakfast dataset, our approach reduces storage by over 500$\times$ while retaining 83\% of the performance compared to training with the full dataset. Furthermore, when applied to a downstream incremental learning task, it yields superior performance compared to the state-of-the-art.
#~~~
#{}{raw}
#<iframe width="560" height="315" src="https://www.youtube.com/embed/04mXlynNDqs" frameborder="0" allowfullscreen></iframe>
#~~~

== Resources
Files: \[[../../papers/ding2025condensing.pdf pdf]\]

Supp: \[[../../papers/ding2025condensing_supp.pdf pdf]\]

Citation:
~~~
@inproceedings{ding2025condensing,\n
  title={Condensing Action Segmentation Datasets via Generative Network Inversion},\n
  author={Ding, Guodong and Chen, Rongyu and Yao, Angela},\n
  booktitle={Computer Vision and Pattern Recognition},\n
  year={2025}\n
}\n
~~~

