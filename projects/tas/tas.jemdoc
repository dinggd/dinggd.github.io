# jemdoc: addcss{../project.css}
# jemdoc: nofooter
= Temporal Action Segmentation: An Analysis of Modern Technique

~~~
{}{img_left}{tas.png}{}{607px}{297px}{}
~~~

== Authors
[http://www.guodongding.cn Guodong Ding] {{<sup>}}1{{</sup>}}, Fadime Sener {{<sup>}}2{{</sup>}} and [https://www.comp.nus.edu.sg/~ayao/ Angela Yao]{{<sup>}}1{{</sup>}} {{<br>}} {{<sup>}}1{{</sup>}}National University of Singapore, {{<sup>}}2{{</sup>}} Reality Labs, Meta
== Abstract
Temporal action segmentation (TAS) from videos aims at densely identifying video frames in minutes-long videos with multiple action classes. As a long-range video understanding task, researchers have developed an extended collection of methods and examined their performance using various benchmarks. Despite the rapid growth of TAS techniques in recent years, no systematic survey has been conducted in these sectors. In this survey, we analyze and summarize the most significant contributions and trends to this endeavor. In particular, we first examine the task definition, common benchmarks, types of supervision, and prevalent evaluation measures. In addition, we systematically investigate two essential techniques of this topic, i.e., frame representation, and temporal modeling, which have been studied extensively in the literature. We then conduct a thorough review of existing TAS works categorized by their levels of supervision and conclude our survey by identifying and emphasizing several research gaps. In addition, we have curated a list of TAS resources, which is available at [https://github.com/atlas-eccv22/awesome-temporal-action-segmentation here].

== Resources
Files: \[[https://arxiv.org/pdf/2210.10352.pdf pdf]\]

Resources: \[[https://github.com/atlas-eccv22/awesome-temporal-action-segmentation GitHub]\]

Citation:
~~~
@article{ding2022temporal,\n
  title={Temporal Action Segmentation: An Analysis of Modern Technique},\n
  author={Ding, Guodong and Sener Fadime and Yao, Angela},\n
  journal={arXiv preprint arXiv:2210.10352},\n
  year={2022}\n
}\n
~~~

