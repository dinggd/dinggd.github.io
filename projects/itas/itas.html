<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.1//EN"
  "http://www.w3.org/TR/xhtml11/DTD/xhtml11.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" xml:lang="en">
<head>
<meta name="generator" content="jemdoc, see http://jemdoc.jaboc.net/" />
<meta http-equiv="Content-Type" content="text/html;charset=utf-8" />
<link rel="stylesheet" href="jemdoc.css" type="text/css" />
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/4.7.0/css/font-awesome.min.css">
<link rel="stylesheet" href="../project.css" type="text/css" />
<title>Coherent Temporal Synthesis for Incremental Action Segmentation</title>
<!-- MathJax -->
<script src='https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/latest.js?config=TeX-MML-AM_CHTML' async>
</script>
<script type="text/x-mathjax-config">
MathJax.Hub.Config({
	  TeX: { equationNumbers: { autoNumber: "AMS" } }
});
</script>
<!-- End MathJax -->
</head>
<body>
<div id="layout-content">
<div id="toptitle">
<h1>Coherent Temporal Synthesis for Incremental Action Segmentation</h1>
</div>
<table class="imgtable"><tr><td>
<img src="itas.jpg" alt="" width="707px" height="297px" />&nbsp;</td>
<td align="left"></td></tr></table>
<h2>Authors</h2>
<p><a href="http://www.guodongding.cn" target=&ldquo;blank&rdquo;>Guodong Ding</a>, Hans Golong and <a href="https://www.comp.nus.edu.sg/~ayao/" target=&ldquo;blank&rdquo;>Angela Yao</a> <br> National University of Singapore
</p>
<h2>Abstract</h2>
<p>Data replay is a successful incremental learning technique for images. It prevents catastrophic forgetting by keeping a reservoir of previous data, original or synthesized, to ensure the model retains past knowledge while adapting to novel concepts. However, its application in the video domain is rudimentary, as it simply stores frame exemplars for action recognition. 
This paper presents the first exploration of video data replay techniques for incremental action segmentation, focusing on action temporal modeling. We propose a Temporally Coherent Action (TCA) model, which represents actions using a generative model instead of storing individual frames. The integration of a conditioning variable that captures temporal coherence allows our model to understand the evolution of action features over time. Therefore, action segments generated by TCA for replay are diverse and temporally coherent. In a 10-task incremental setup on the Breakfast dataset, our approach achieves significant increases in accuracy for up to 22% compared to the baselines. 
</p>
<iframe width="560" height="315" src="https://www.youtube.com/embed/04mXlynNDqs" frameborder="0" allowfullscreen></iframe>
<h2>Resources</h2>
<p>Files: [<a href="../../papers/ding2024coherent.pdf" target=&ldquo;blank&rdquo;>pdf</a>]
</p>
<p>Citation:
</p>
<div class="infoblock">
<div class="blockcontent">
<p>@inpr{ding2024coherent,<br />
title={Coherent Temporal Synthesis for Incremental Action Segmentation},<br />
author={Ding, Guodong and Golong, Hans and Yao, Angela},<br />
booktitle={Computer Vision and Pattern Recognition},<br />
year={2024}<br />
}<br />
</p>
</div></div>
</div>
