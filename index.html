<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.1//EN"
  "http://www.w3.org/TR/xhtml11/DTD/xhtml11.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" xml:lang="en">
<head>
<meta name="generator" content="jemdoc, see http://jemdoc.jaboc.net/" />
<meta http-equiv="Content-Type" content="text/html;charset=utf-8" />
<link rel="stylesheet" href="jemdoc.css" type="text/css" />
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/4.7.0/css/font-awesome.min.css">
<link rel="stylesheet" href="jemdoc.css" type="text/css" />
<title>Guodong Ding's Homepage</title>
<!-- MathJax -->
<script src='https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/latest.js?config=TeX-MML-AM_CHTML' async>
</script>
<script type="text/x-mathjax-config">
MathJax.Hub.Config({
	  TeX: { equationNumbers: { autoNumber: "AMS" } }
});
</script>
<!-- End MathJax -->
</head>
<body>
<table summary="Table for page layout." id="tlayout">
<tr valign="top">
<td id="layout-menu">
<div class="menu-item"><a href="index.html" class="current">Home</a></div>
<div class="menu-item"><a href="projects.html">Projects</a></div>
<div class="menu-item"><a href="publications.html">Publications</a></div>
</td>
<td id="layout-content">
<div id="toptitle">
<h1>Guodong Ding's Homepage</h1>
</div>
<table class="imgtable"><tr><td>
<img src="avatar.jpeg" alt="profolio" width="150px" height="150px" />&nbsp;</td>
<td align="left"><h2>Guodong Ding (Ph.D) 丁国栋 [<a href="./files/GUODONG_DING_CV.pdf" target=&ldquo;blank&rdquo;>CV</a>]<br /></h2>
<p>dinggd <i>[at</i>] comp.nus.edu <i>[dot</i>] sg<br />
<i>Senior Research Fellow, School of Computing (SoC)</i>, <br />
<i>National University of Singapore (NUS)</i>,<br />
<i>AS6-04-11, 11 Computing Dr, Singapore, 117416</i><br />
</p>
<p><a href="https://scholar.google.com/citations?user=PqlGbTYAAAAJ&hl=en">
<i class="fa fa-fw fa-graduation-cap"></i> Google Scholar</a>
<a href="https://github.com/nus-cvml/awesome-temporal-action-segmentation"><i class="fa fa-fw fa-paper-plane"></i> Awesome-TAS</a>
</p>
</td></tr></table>
<h2>Research Interest</h2>
<p>My current research interest is mainly understanding human actions in long range video sequences, <i>i.e.</i>, <u>Temporal Action Segmentation</u>. I am also interested in learning with weaker forms of data supervisions such as, <u>weakly-supervised</u> and <u>semi-supervised</u> learning.
</p>
<h2>Updates</h2>
<ul>
<li><p><i>[Sep., 24]</i> One conference paper accepted to NeurIPS 2024, congrats to Qing!
</p>
</li>
<li><p><i>[Jun., 24]</i> I will be serving as Senior Program Committee for AAAI 2024.
</p>
</li>
<li><p><i>[Apr., 24]</i> One extended abstract accepted to CVPR2024 Workshop LPVL2024.
</p>
</li>
<li><p><i>[Feb., 24]</i> One conference paper accepted to CVPR2024.
</p>
</li>
<li><p><i>[Oct., 23]</i> One survey paper accpeted to TPAMI.
</p>
</li>
<li><p><i>[Dec., 22]</i> One journal paper accpetd to TMM.
</p>
</li>
</ul>
<h2>Employment</h2>
<ul>
<li><p><b>Senior Research Fellow</b> <i>(Oct., 23 - Present)</i>, in School of Computing (SoC), National University of Singapore, Singapore. 
</p>
</li>
<li><p><b>Research Fellow</b> <i>(Oct., 20 - Oct., 23)</i>, in School of Computing (SoC), National University of Singapore, Singapore. 
</p>
</li>
<li><p><b>Engineering Intern</b> <i>(June, 19 - Sept., 19)</i>, in China QCT MM R&amp;D, Qualcomm Shanghai, China. 
</p>
</li>
</ul>
<h2>Research Experiences</h2>
<ul>
<li><p><b>Visiting Scholar</b> <i>(Feb., 17 - Oct., 17)</i>, in Australian National University, Australia.
</p>
</li>
<li><p><b>Research Assistant</b> <i>(Nov., 15 - Feb., 17)</i>, in the Hong Kong Polytechnic University, Hong Kong, China.
</p>
</li>
</ul>
<h2>Adivsed Students</h2>
<ul>
<li><p>Alberto Mate (2024, Master, Universitat Politècnica de Catalunya)
</p>
</li>
<li><p>Qing Zhong (2024, PhD, University of Adelaide)
</p>
</li>
<li><p>Hans Golong (2023 - 2024, Master, National University of Singapore)
</p>
</li>
</ul>
<h2>Publications</h2>
<p><a href="https://scholar.google.com/citations?hl=en&amp;user=PqlGbTYAAAAJ" target=&ldquo;blank&rdquo;>[Google Scholar]</a> (<b>*</b>: corresponding author, <i><u>underlined</u></i>: supervised student)<br />
</p>
<h3>Conference papers</h3>
<ul>
<li><p><u>Q. Zhong</u>, <b>G. Ding</b>, and A. Yao, &ldquo;OnlineTAS: An Online Baseline for Temporal Action Segmentation,&rdquo; <i>NeurIPS</i> 2024. <a href="https://arxiv.org/pdf/2307.16453.pdf" target=&ldquo;blank&rdquo;>[pdf]</a>|<a href="projects/misdet/misdet.html" target=&ldquo;blank&rdquo;>[project page]</a>|<a href="https://github.com/assembly-101/assembly101-mistake-detection" target=&ldquo;blank&rdquo;>[annots]</a> 
</p>
</li>
<li><p><b>G. Ding</b>, F. Sener, S. Ma and A. Yao,  &ldquo;Ordering Mistake Detection in Assembly Tasks,&rdquo; <i>CVPR Workshop</i> 2024. <a href="https://arxiv.org/pdf/2307.16453.pdf" target=&ldquo;blank&rdquo;>[pdf]</a>|<a href="projects/misdet/misdet.html" target=&ldquo;blank&rdquo;>[project page]</a>|<a href="https://github.com/assembly-101/assembly101-mistake-detection" target=&ldquo;blank&rdquo;>[annots]</a> 
</p>
</li>
<li><p><b>G. Ding</b>, <u>H. Golong</u> and A. Yao, &ldquo;Coherent Temporal Synthesis for Incremental Action Segmentation,&rdquo; <i>Computer Vision and Pattern Recognition</i> 2024. <a href="projects/itas/itas.html" target=&ldquo;blank&rdquo;>[project page]</a>|<a href="papers/ding2024coherent.pdf" target=&ldquo;blank&rdquo;>[pdf]</a>|<a href="https://www.youtube.com/watch?v=04mXlynNDqs" target=&ldquo;blank&rdquo;>[video]</a>|<a href="papers/ding2024coherent_poster.pdf" target=&ldquo;blank&rdquo;>[poster]</a>|<a href="papers/ding2024coherent_slides.pdf" target=&ldquo;blank&rdquo;>[slides]</a>
</p>
</li>
<li><p><b>G. Ding</b> and A. Yao, &ldquo;Leveraging Action Affinity and Continuity for Semi-supervised Temporal Action Segmentation,&rdquo; <i>European Conference on Computer Vision</i> 2022. <a href="projects/semi/semi.html" target=&ldquo;blank&rdquo;>[project page]</a>| <a href="papers/ding2022leveraging.pdf" target=&ldquo;blank&rdquo;>[pdf]</a>|<a href="https://www.youtube.com/watch?v=DmELTZr91fE" target=&ldquo;blank&rdquo;>[video]</a>|<a href="papers/ding2022leveraging_poster.pdf" target=&ldquo;blank&rdquo;>[poster]</a>
</p>
</li>
<li><p><b>G. Ding</b>, S. Khan, and Z. Tang, &ldquo;Dispersion-based Clustering for Unsupervised Person Re-identiﬁcation,&rdquo; <i>British Machine Vision Conference</i>, 2019. <a href="papers/ding2019dispersion.pdf" target=&ldquo;blank&rdquo;>[pdf]</a>|<a href="projects/dbc/dbc.html" target=&ldquo;blank&rdquo;>[project page]</a>
</p>
</li>
<li><p><b>G. Ding*</b>, S. Zhang, S. Khan, and Z. Tang, &ldquo;Center based Pseudo-labeling for Semi-supervised Person Re-identification,&rdquo; <i>International Conference of Multimedia and Expo Workshops</i> 2018. <a href="papers/ding2018center.pdf" target=&ldquo;blank&rdquo;>[pdf]</a>|<a href="papers/ding2018center_slides.pdf" target=&ldquo;blank&rdquo;>[slides]</a>
</p>
</li>
</ul>
<h3>Journal articles</h3>
<ul>
<li><p><b>G. Ding</b>, F. Sener and A. Yao, &ldquo;Temporal Action Segmentation: An Analysis of Modern Techniques,&rdquo; <i>IEEE Transactions on Pattern Analysis and Machine Intelligence</i> 2023. <a href="https://arxiv.org/pdf/2210.10352.pdf" target=&ldquo;blank&rdquo;>[pdf]</a>|<a href="projects/tas/tas.html" target=&ldquo;blank&rdquo;>[project page]</a>|<a href="https://github.com/atlas-eccv22/awesome-temporal-action-segmentation" target=&ldquo;blank&rdquo;>[resources]</a>
</p>
</li>
<li><p><b>G. Ding</b> and A. Yao, &ldquo;Temporal Action Segmentation with High-level Complex Activity Labels,&rdquo; <i>IEEE Transcations on Multimedia</i> 2022.  <a href="https://arxiv.org/pdf/2108.06706.pdf" target=&ldquo;blank&rdquo;>[pdf]</a>|<a href="projects/cad/cad.html" target=&ldquo;blank&rdquo;>[project page]</a>
</p>
</li>
<li><p>Q. Yin, G. Wang, <b>G. Ding</b>, Q. Li, S. Gong and Z. Tang, &ldquo;Rapid Person Re-Identification via Sub-space Consistency Regularization,&rdquo; <i>Neural Processing Letters</i> 2022. <a href="https://arxiv.org/pdf/2207.05933.pdf" target=&ldquo;blank&rdquo;>[pdf]</a>|<a href="projects/scr/scr.html" target=&ldquo;blank&rdquo;>[project page]</a>
</p>
</li>
<li><p>Q. Yin, G. Wang, <b>G. Ding</b>, S. Gong and Z. Tang, &ldquo;Multi-View Label Prediction for Unsupervsied Person Re-identification,&rdquo; <i>IEEE Singal Processing Letters</i> 2021.  <a href="http://www.eecs.qmul.ac.uk/~sgg/papers/YinEtAl_SPL2021.pdf" target=&ldquo;blank&rdquo;>[pdf]</a>|<a href="projects/mvreid/mvreid.html" target=&ldquo;blank&rdquo;>[project page]</a>
</p>
</li>
<li><p><b>G. Ding*</b>, S. Zhang, S. Khan, Z. Tang, J. Zhang and F. Porikli, &ldquo;Feature Affinity based Pseudo Labeling for Semi-supervised Person Re-identification,&rdquo; <i>IEEE Transcations on Multimedia</i> 2019.  <a href="papers/ding2019a.pdf" target=&ldquo;blank&rdquo;>[pdf]</a>|<a href="projects/fapl/fapl.html" target=&ldquo;blank&rdquo;>[project page]</a>
</p>
</li>
<li><p><b>G. Ding*</b>, S. Khan, Z. Tang, and F. Porikli, &ldquo;Feature Mask Network for Person Re-identification,&rdquo; <i>Pattern Recognition Letters</i> 2019. <a href="papers/ding2019feature.pdf" target=&ldquo;blank&rdquo;>[pdf]</a>|<a href="projects/fmn/fmn.html" target=&ldquo;blank&rdquo;>[project page]</a>
</p>
</li>
</ul>
<h3>Preprints</h3>
<ul>
<li><p><b>G. Ding*</b>, S. Khan, Z. Tang, J. Zhang and F. Porikli, Towards better Validity: Dispersion based Clustering for Unsupervised Person Re-identification, <i>Arxiv paper</i> 2019.  <a href="https://arxiv.org/pdf/1906.01308.pdf" target=&ldquo;blank&rdquo;>[pdf]</a>|<a href="https://github.com/gddingcs/Dispersion-based-Clustering" target=&ldquo;blank&rdquo;>[code]</a>|<a href="projects/dbc/dbc.html" target=&ldquo;blank&rdquo;>[project page]</a>
</p>
</li>
</ul>
<h2>Reviewer</h2>
<h3>Journal:</h3>
<p>IEEE Transactions on Pattern Analysis and Machine Intelligence (TPAMI)<br />
IEEE Transactions on Multimedia (TMM)<br />
IEEE Transactions on Image Processing (TIP)<br />
IEEE Transactions on Circuits and Systems for Video Technology (TCSVT)<br />
ACM Transactions on Sensor Networks (TOSN)<br />
IEEE Transactions on Industrial Informatics (TII)<br />
</p>
<h3>Conference:</h3>
<p>IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR) (2021 - 2024)<br />
European Conference on Computer Vision (ECCV) (2020, 2022, 2024)<br />
IEEE/CVF International Conference on Computer Vision (ICCV) (2021, 2023)<br />
Advances in Neural Information Processing Systems (NeurIPS) (2023 - 2024)<br />
AAAI Conference on Artificial Intelligence (AAAI) (2023 - 2024) <br />
British Machine Vision Conference (BMVC) (2020 - 2024) <br />
</p>
<h2>Service</h2>
<p>Area Chair (SPC), AAAI 2024.<br />
Tutorial (<a href="https://nus-cvml.github.io/atlas-eccv22/" target=&ldquo;blank&rdquo;>ATLAS</a>) Organizer , ECCV 2022.<br />
</p>
<h2>Collaborators</h2>
<p>Prof. <a href="https://www.comp.nus.edu.sg/~ayao/" target=&ldquo;blank&rdquo;>Angela Yao</a>, School of Computing, National University of Singapore<br />
Dr. <a href="https://scholar.google.com/citations?user=-juoweoAAAAJ&amp;hl=en" target=&ldquo;blank&rdquo;>Fadime Sener</a>, Reality Labs Research, Meta<br />
Prof. <a href="https://salman-h-khan.github.io/" target=&ldquo;blank&rdquo;>Salman Khan</a>, MBZUAI & Australian National University<br />
Prof. <a href="https://www.uts.edu.au/staff/jian.zhang" target=&ldquo;blank&rdquo;>Jian Zhang</a>, University of Technology Sydney<br />
Prof. <a href="http://www.porikli.com/" target=&ldquo;blank&rdquo;>Fatih Porikli</a>, Qualcomm, USA<br /> 
Prof. <a href="https://shanshanzhang.github.io/" target=&ldquo;blank&rdquo;>Shanshan Zhang</a>, Nanjing University of Science and Technology<br />
</p>
<h2></h2>
<img src="logos/njust066.png" alt="njust_logo" height ="40px" hspace="5px"/>
<img src="logos/polyu066.png" alt="polyu_logo" height ="40px" hspace="5px"/>
<img src="logos/anu066.png" alt="anu_logo" height ="40px" hspace="5px"/>
<img src="logos/nussoc.png" alt="nus_logo" height="40px" hspace="5px"/>
<script type='text/javascript' id='clustrmaps' src='//cdn.clustrmaps.com/map_v2.js?cl=ffffff&w=300&t=tt&d=t4RbYEuOvtUrPAOHAA8tfAeyYzchA76o7ZHmArZ7XfQ'></script>

</td>
</tr>
</table>
