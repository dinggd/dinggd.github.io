<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.1//EN"
  "http://www.w3.org/TR/xhtml11/DTD/xhtml11.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" xml:lang="en">
<head>
<meta name="generator" content="jemdoc, see http://jemdoc.jaboc.net/" />
<meta http-equiv="Content-Type" content="text/html;charset=utf-8" />
<link rel="stylesheet" href="jemdoc.css" type="text/css" />
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/4.7.0/css/font-awesome.min.css">
<link rel="stylesheet" href="jemdoc.css" type="text/css" />
<title>Guodong Ding's Homepage</title>
<!-- MathJax -->
<script src='https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/latest.js?config=TeX-MML-AM_CHTML' async>
</script>
<script type="text/x-mathjax-config">
MathJax.Hub.Config({
	  TeX: { equationNumbers: { autoNumber: "AMS" } }
});
</script>
<!-- End MathJax -->
</head>
<body>
<div id="layout-content">
<div id="toptitle">
<h1>Guodong Ding's Homepage</h1>
</div>
<table class="imgtable"><tr><td>
<img src="avatar.jpeg" alt="profolio" width="150px" height="150px" />&nbsp;</td>
<td align="left"><h2>Guodong Ding (Ph.D) 丁国栋 [<a href="./files/GUODONG_DING_CV.pdf" target=&ldquo;blank&rdquo;>CV</a>]<br /></h2>
<p>dinggd <i>[at</i>] comp.nus.edu <i>[dot</i>] sg<br />
<i>Senior Research Fellow, School of Computing (SoC)</i>, <br />
<i>National University of Singapore (NUS)</i>,<br />
<i>AS6-04-11, 11 Computing Dr, Singapore, 117416</i><br />
</p>
<p>
<a href="https://scholar.google.com/citations?user=PqlGbTYAAAAJ&hl=en">
<i class="fa fa-fw fa-graduation-cap"></i> Google Scholar</a>

</p>
</td></tr></table>
<h2>Research Interest</h2>
<p>My current research interest is mainly understanding human actions in long range video sequences, <i>i.e.</i>, <u>Temporal Action Segmentation</u>. I am also interested in learning with weaker forms of data supervisions such as, <u>weakly-supervised</u> and <u>semi-supervised</u> learning.
</p>
<h2>Updates</h2>
<ul>
<li><p><i>[Apr., 25]</i> One extended abstract accepted to CVPR2024 Workshop LPVL2024.
</p>
</li>
<li><p><i>[Feb., 24]</i> One conference paper accepted to CVPR2024.
</p>
</li>
<li><p><i>[Oct., 23]</i> One survey paper accpeted to TPAMI.
</p>
</li>
<li><p><i>[Dec., 22]</i> One journal paper accpetd to TMM.
</p>
</li>
</ul>
<h2>Employment</h2>
<ul>
<li><p><b>Senior Research Fellow</b> <i>(Oct., 23 - Present)</i>, in School of Computing (SoC), National University of Singapore, Singapore. 
</p>
</li>
<li><p><b>Research Fellow</b> <i>(Oct., 20 - Oct., 23)</i>, in School of Computing (SoC), National University of Singapore, Singapore. 
</p>
</li>
<li><p><b>Engineering Intern</b> <i>(June, 19 - Sept., 19)</i>, in China QCT MM R&amp;D, Qualcomm Shanghai, China. 
</p>
</li>
</ul>
<h2>Research Experiences</h2>
<ul>
<li><p><b>Visiting Scholar</b> <i>(Feb., 17 - Oct., 17)</i>, in Australian National University, Australia.
</p>
</li>
<li><p><b>Research Assistant</b> <i>(Nov., 15 - Feb., 17)</i>, in the Hong Kong Polytechnic University, Hong Kong, China.
</p>
</li>
</ul>
<h2>Education</h2>
<ul>
<li><p><b>Ph.D.</b> <i>(Sept. 2013 - Jan. 2020)</i>, in Computer Science and Technology (081200),<br /> 
Nanjing University of Science and Technology, Nanjing <br />
Advisor: Prof. <a href="http://202.119.85.163/open/TutorInfo.aspx?dsbh=21087&amp;yxsh=106&amp;zydm=081203" target=&ldquo;blank&rdquo;>Zhenmin Tang</a> and Prof. Guangyi Bai,<br />
博士论文: <i>面向不同监督条件下的行人再识别深度学习方法关键问题研究</i>&nbsp;[<a href="files/Dissertation.pdf" target=&ldquo;blank&rdquo;>pdf</a>],<br />
Dissertation: <i>Research on Deep Learning based Person Re-identification Methods under Different Supervisions</i>
</p>
</li>
<li><p><b>B.Eng.</b> <i>(Sept. 2009- June. 2013)</i>, in Computer Science and Technology (080605),<br />
Nanjing University of Science and Technology, Nanjing<br />
Advisor: Prof. <a href="http://202.119.85.163/open/TutorInfo.aspx?dsbh=21087&amp;yxsh=106&amp;zydm=081203" target=&ldquo;blank&rdquo;>Zhenmin Tang</a>,<br />
本科论文: <i>基于内容的商品图像检索</i>,<br />
Thesis: <i>Content based Commodity Image Retrieval</i>
</p>
</li>
</ul>
<h2>Publications</h2>
<p>[<a href="https://scholar.google.com/citations?hl=en&amp;user=PqlGbTYAAAAJ" target=&ldquo;blank&rdquo;>Google Scholar</a>]  <br />
</p>
<h3>Preprints &amp; working papers</h3>
<ul>
<li><p><b>G. Ding*</b>, S. Khan, Z. Tang, J. Zhang and F. Porikli, Towards better Validity: Dispersion based Clustering for Unsupervised Person Re-identification, <i>Arxiv paper</i> 2019.  [<a href="https://arxiv.org/pdf/1906.01308.pdf" target=&ldquo;blank&rdquo;>pdf</a>]|[<a href="https://github.com/gddingcs/Dispersion-based-Clustering" target=&ldquo;blank&rdquo;>code</a>]|[<a href="projects/dbc/dbc.html" target=&ldquo;blank&rdquo;>project page</a>]
</p>
</li>
</ul>
<h3>Journal articles</h3>
<ul>
<li><p><b>G. Ding</b>, F. Sener and A. Yao, Temporal Action Segmentation: An Analysis of Modern Techniques, <i>IEEE Transactions on Pattern Analysis and Machine Intelligence</i> 2023. [<a href="https://arxiv.org/pdf/2210.10352.pdf" target=&ldquo;blank&rdquo;>pdf</a>]|[<a href="projects/tas/tas.html" target=&ldquo;blank&rdquo;>project page</a>]|[<a href="https://github.com/atlas-eccv22/awesome-temporal-action-segmentation" target=&ldquo;blank&rdquo;>resources</a>]
</p>
</li>
<li><p><b>G. Ding</b> and A. Yao, Temporal Action Segmentation with High-level Complex Activity Labels, <i>IEEE Transcations on Multimedia</i> 2022.  [<a href="https://arxiv.org/pdf/2108.06706.pdf" target=&ldquo;blank&rdquo;>pdf</a>]|[<a href="projects/cad/cad.html" target=&ldquo;blank&rdquo;>project page</a>]
</p>
</li>
<li><p>Q. Yin, G. Wang, <b>G. Ding</b>, Q. Li, S. Gong and Z. Tang, Rapid Person Re-Identification via Sub-space Consistency Regularization, <i>Neural Processing Letters</i> 2022. [<a href="https://arxiv.org/pdf/2207.05933.pdf" target=&ldquo;blank&rdquo;>pdf</a>]|[<a href="projects/scr/scr.html" target=&ldquo;blank&rdquo;>project page</a>]
</p>
</li>
<li><p>Q. Yin, G. Wang, <b>G. Ding</b>, S. Gong and Z. Tang, Multi-View Label Prediction for Unsupervsied Person Re-identification, <i>IEEE Singal Processing Letters</i> 2021.  [<a href="http://www.eecs.qmul.ac.uk/~sgg/papers/YinEtAl_SPL2021.pdf" target=&ldquo;blank&rdquo;>pdf</a>]|[<a href="projects/mvreid/mvreid.html" target=&ldquo;blank&rdquo;>project page</a>]
</p>
</li>
<li><p><b>G. Ding*</b>, S. Zhang, S. Khan, Z. Tang, J. Zhang and F. Porikli, Feature Affinity based Pseudo Labeling for Semi-supervised Person Re-identification, <i>IEEE Transcations on Multimedia</i> 2019.  [<a href="papers/ding2019a.pdf" target=&ldquo;blank&rdquo;>pdf</a>]|[<a href="projects/fapl/fapl.html" target=&ldquo;blank&rdquo;>project page</a>]
</p>
</li>
<li><p><b>G. Ding*</b>, S. Khan, Z. Tang, and F. Porikli, Feature Mask Network for Person Re-identification, <i>Pattern Recognition Letters</i> 2019. [<a href="papers/ding2019feature.pdf" target=&ldquo;blank&rdquo;>pdf</a>]|[<a href="projects/fmn/fmn.html" target=&ldquo;blank&rdquo;>project page</a>]
</p>
</li>
</ul>
<h3>Conference papers</h3>
<ul>
<li><p><b>G. Ding</b>, F. Sener, S. Ma and A. Yao,  Ordering Mistake Detection in Assembly Tasks, <i>CVPR Workshop</i> 2024. [<a href="https://arxiv.org/pdf/2307.16453.pdf" target=&ldquo;blank&rdquo;>pdf</a>]|[<a href="projects/misdet/misdet.html" target=&ldquo;blank&rdquo;>project page</a>]|[<a href="https://github.com/assembly-101/assembly101-mistake-detection" target=&ldquo;blank&rdquo;>annots</a>] 
</p>
</li>
<li><p><b>G. Ding</b>, <u>H. Golong</u> and A. Yao, Coherent Temporal Synthesis for Incremental Action Segmentation, <i>Computer Vision and Pattern Recognition</i> 2024. [<a href="papers/ding2024coherent.pdf" target=&ldquo;blank&rdquo;>pdf</a>]|[<a href="projects/itas/itas.html" target=&ldquo;blank&rdquo;>project page</a>]|[<a href="https://www.youtube.com/watch?v=04mXlynNDqs" target=&ldquo;blank&rdquo;>video</a>]|[<a href="papers/ding2024coherent_poster.pdf" target=&ldquo;blank&rdquo;>poster</a>]|[<a href="papers/ding2024coherent_slides.pdf" target=&ldquo;blank&rdquo;>slides</a>]
</p>
</li>
<li><p><b>G. Ding</b> and A. Yao, Leveraging Action Affinity and Continuity for Semi-supervised Temporal Action Segmentation, <i>European Conference on Computer Vision</i> 2022.  [<a href="papers/ding2022leveraging.pdf" target=&ldquo;blank&rdquo;>pdf</a>]|[<a href="papers/ding2022leveraging_poster.pdf" target=&ldquo;blank&rdquo;>poster</a>]|[<a href="projects/semi/semi.html" target=&ldquo;blank&rdquo;>project page</a>]
</p>
</li>
<li><p><b>G. Ding*</b>, S. Zhang, S. Khan, and Z. Tang, Center based Pseudo-labeling for Semi-supervised Person Re-identification, <i>International Conference of Multimedia and Expo Workshops</i> 2018. [<a href="papers/ding2018center.pdf" target=&ldquo;blank&rdquo;>pdf</a>]|[<a href="papers/ding2018center_slides.pdf" target=&ldquo;blank&rdquo;>slides</a>]
</p>
</li>
</ul>
<p>(<b>*</b>: corresponding author, <i><u>underlined</u></i>: supervised student)<br />
</p>
<h2>Reviewer</h2>
<h3>Journal:</h3>
<p>TPAMI, TMM, TIP, TOSN, TII <br />
</p>
<h3>Conference:</h3>
<p>CVPR, ECCV, ICCV, AAAI, BMVC, ICME<br />
Co-organizer of <a href="https://nus-cvml.github.io/atlas-eccv22/" target=&ldquo;blank&rdquo;>ATLAS</a> Tutorial on understanding actions in long untrimmed videos in conjunction with ECCV2022.
</p>
<h2>Collaborators</h2>
<p>Prof. <a href="https://www.comp.nus.edu.sg/~ayao/" target=&ldquo;blank&rdquo;>Angela Yao</a>, School of Computing, National University of Singapore<br />
Prof. <a href="https://salman-h-khan.github.io/" target=&ldquo;blank&rdquo;>Salman Khan</a>, MBZUAI<br />
Prof. <a href="https://www.uts.edu.au/staff/jian.zhang" target=&ldquo;blank&rdquo;>Jian Zhang</a>, University of Technology Sydney<br />
Prof. <a href="http://www.porikli.com/" target=&ldquo;blank&rdquo;>Fatih Porikli</a>, Australian National University and FutureWei, USA<br /> 
Prof. <a href="https://sites.google.com/site/shanshanzhangshomepage/" target=&ldquo;blank&rdquo;>Shanshan Zhang</a>, Nanjing University of Science and Technology<br />
</p>
<h2></h2>
<img src="logos/njust066.png" alt="njust_logo" height ="40px" hspace="5px"/>
<img src="logos/polyu066.png" alt="polyu_logo" height ="40px" hspace="5px"/>
<img src="logos/anu066.png" alt="anu_logo" height ="40px" hspace="5px"/>
<img src="logos/nussoc.png" alt="nus_logo" height="40px" hspace="5px"/>
<script type='text/javascript' id='clustrmaps' src='//cdn.clustrmaps.com/map_v2.js?cl=ffffff&w=300&t=tt&d=t4RbYEuOvtUrPAOHAA8tfAeyYzchA76o7ZHmArZ7XfQ'></script>

</div>
